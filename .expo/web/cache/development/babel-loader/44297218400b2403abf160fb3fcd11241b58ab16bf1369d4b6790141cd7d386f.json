{"ast":null,"code":"import _asyncToGenerator from \"@babel/runtime/helpers/asyncToGenerator\";\nimport _classCallCheck from \"@babel/runtime/helpers/classCallCheck\";\nimport _createClass from \"@babel/runtime/helpers/createClass\";\nfunction _asyncIterator(r) { var n, t, o, e = 2; for (\"undefined\" != typeof Symbol && (t = Symbol.asyncIterator, o = Symbol.iterator); e--;) { if (t && null != (n = r[t])) return n.call(r); if (o && null != (n = r[o])) return new AsyncFromSyncIterator(n.call(r)); t = \"@@asyncIterator\", o = \"@@iterator\"; } throw new TypeError(\"Object is not async iterable\"); }\nfunction AsyncFromSyncIterator(r) { function AsyncFromSyncIteratorContinuation(r) { if (Object(r) !== r) return Promise.reject(new TypeError(r + \" is not an object.\")); var n = r.done; return Promise.resolve(r.value).then(function (r) { return { value: r, done: n }; }); } return AsyncFromSyncIterator = function AsyncFromSyncIterator(r) { this.s = r, this.n = r.next; }, AsyncFromSyncIterator.prototype = { s: null, n: null, next: function next() { return AsyncFromSyncIteratorContinuation(this.n.apply(this.s, arguments)); }, return: function _return(r) { var n = this.s.return; return void 0 === n ? Promise.resolve({ value: r, done: !0 }) : AsyncFromSyncIteratorContinuation(n.apply(this.s, arguments)); }, throw: function _throw(r) { var n = this.s.return; return void 0 === n ? Promise.reject(r) : AsyncFromSyncIteratorContinuation(n.apply(this.s, arguments)); } }, new AsyncFromSyncIterator(r); }\nimport OpenAI from 'openai';\nimport Anthropic from '@anthropic-ai/sdk';\nvar AIService = function () {\n  function AIService() {\n    _classCallCheck(this, AIService);\n    this.openAIClient = null;\n    this.anthropicClient = null;\n    this.customClient = null;\n    this.currentProvider = 'openai';\n    this.baseUrl = null;\n    this.loadSavedConfig();\n  }\n  return _createClass(AIService, [{\n    key: \"loadSavedConfig\",\n    value: function loadSavedConfig() {\n      var savedConfig = localStorage.getItem('ai_service_config');\n      if (savedConfig) {\n        var config = JSON.parse(savedConfig);\n        this.configure(config).catch(console.error);\n      }\n    }\n  }, {\n    key: \"configure\",\n    value: function () {\n      var _configure = _asyncToGenerator(function* (config) {\n        try {\n          switch (config.provider) {\n            case 'openai':\n              this.openAIClient = new OpenAI({\n                apiKey: config.apiKey,\n                dangerouslyAllowBrowser: true\n              });\n              yield this.openAIClient.models.list();\n              break;\n            case 'anthropic':\n              this.anthropicClient = new Anthropic({\n                apiKey: config.apiKey\n              });\n              break;\n            case 'custom':\n              if (!config.baseUrl) {\n                throw new Error('Base URL is required for custom provider');\n              }\n              this.customClient = new OpenAI({\n                apiKey: config.apiKey || 'not-needed',\n                baseURL: config.baseUrl,\n                dangerouslyAllowBrowser: true\n              });\n              break;\n          }\n          this.currentProvider = config.provider;\n          this.baseUrl = config.baseUrl || null;\n          localStorage.setItem('ai_service_config', JSON.stringify({\n            provider: config.provider,\n            apiKey: config.apiKey,\n            baseUrl: config.baseUrl\n          }));\n        } catch (error) {\n          throw new Error(`Failed to configure AI service: ${error.message}`);\n        }\n      });\n      function configure(_x) {\n        return _configure.apply(this, arguments);\n      }\n      return configure;\n    }()\n  }, {\n    key: \"getAvailableModels\",\n    value: function () {\n      var _getAvailableModels = _asyncToGenerator(function* () {\n        try {\n          switch (this.currentProvider) {\n            case 'openai':\n              if (this.openAIClient) {\n                var response = yield this.openAIClient.models.list();\n                return response.data.map(function (model) {\n                  return {\n                    id: model.id,\n                    name: model.id,\n                    provider: 'openai'\n                  };\n                });\n              }\n              break;\n            case 'anthropic':\n              if (this.anthropicClient) {\n                return [{\n                  id: 'claude-2',\n                  name: 'Claude 2',\n                  provider: 'anthropic'\n                }, {\n                  id: 'claude-instant-1',\n                  name: 'Claude Instant',\n                  provider: 'anthropic'\n                }];\n              }\n              break;\n            case 'custom':\n              if (this.customClient) {\n                try {\n                  var _response = yield this.customClient.models.list();\n                  return _response.data.map(function (model) {\n                    return {\n                      id: model.id,\n                      name: model.id,\n                      provider: 'custom'\n                    };\n                  });\n                } catch (error) {\n                  return [{\n                    id: 'default-model',\n                    name: 'Default Model',\n                    provider: 'custom'\n                  }];\n                }\n              }\n              break;\n          }\n          return [];\n        } catch (error) {\n          console.error('Failed to fetch models:', error);\n          return [];\n        }\n      });\n      function getAvailableModels() {\n        return _getAvailableModels.apply(this, arguments);\n      }\n      return getAvailableModels;\n    }()\n  }, {\n    key: \"generateText\",\n    value: function () {\n      var _generateText = _asyncToGenerator(function* (prompt) {\n        var options = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {};\n        try {\n          switch (this.currentProvider) {\n            case 'openai':\n              if (this.openAIClient) {\n                return this.handleOpenAIGeneration(prompt, options);\n              }\n              break;\n            case 'anthropic':\n              if (this.anthropicClient) {\n                return this.handleAnthropicGeneration(prompt, options);\n              }\n              break;\n            case 'custom':\n              if (this.customClient) {\n                return this.handleOpenAIGeneration(prompt, options, this.customClient);\n              }\n              break;\n          }\n          throw new Error('No AI provider configured');\n        } catch (error) {\n          throw new Error(`AI generation failed: ${error.message}`);\n        }\n      });\n      function generateText(_x2) {\n        return _generateText.apply(this, arguments);\n      }\n      return generateText;\n    }()\n  }, {\n    key: \"handleOpenAIGeneration\",\n    value: function () {\n      var _handleOpenAIGeneration = _asyncToGenerator(function* (prompt, options) {\n        var client = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : this.openAIClient;\n        var response = yield client.chat.completions.create({\n          model: options.model || 'gpt-3.5-turbo',\n          messages: [{\n            role: 'user',\n            content: prompt\n          }],\n          temperature: options.temperature,\n          max_tokens: options.maxTokens,\n          stream: options.stream\n        });\n        if (options.stream) {\n          var fullResponse = '';\n          var _iteratorAbruptCompletion = false;\n          var _didIteratorError = false;\n          var _iteratorError;\n          try {\n            for (var _iterator = _asyncIterator(response), _step; _iteratorAbruptCompletion = !(_step = yield _iterator.next()).done; _iteratorAbruptCompletion = false) {\n              var chunk = _step.value;\n              {\n                var _chunk$choices$, _chunk$choices$$delta;\n                var content = ((_chunk$choices$ = chunk.choices[0]) == null ? void 0 : (_chunk$choices$$delta = _chunk$choices$.delta) == null ? void 0 : _chunk$choices$$delta.content) || '';\n                fullResponse += content;\n                options.onToken == null ? void 0 : options.onToken(content);\n              }\n            }\n          } catch (err) {\n            _didIteratorError = true;\n            _iteratorError = err;\n          } finally {\n            try {\n              if (_iteratorAbruptCompletion && _iterator.return != null) {\n                yield _iterator.return();\n              }\n            } finally {\n              if (_didIteratorError) {\n                throw _iteratorError;\n              }\n            }\n          }\n          return fullResponse;\n        } else {\n          var _response$choices$, _response$choices$$me;\n          return ((_response$choices$ = response.choices[0]) == null ? void 0 : (_response$choices$$me = _response$choices$.message) == null ? void 0 : _response$choices$$me.content) || '';\n        }\n      });\n      function handleOpenAIGeneration(_x3, _x4) {\n        return _handleOpenAIGeneration.apply(this, arguments);\n      }\n      return handleOpenAIGeneration;\n    }()\n  }, {\n    key: \"handleAnthropicGeneration\",\n    value: function () {\n      var _handleAnthropicGeneration = _asyncToGenerator(function* (prompt, options) {\n        var response = yield this.anthropicClient.messages.create({\n          model: options.model || 'claude-2',\n          max_tokens: options.maxTokens,\n          messages: [{\n            role: 'user',\n            content: prompt\n          }]\n        });\n        return response.content[0].text;\n      });\n      function handleAnthropicGeneration(_x5, _x6) {\n        return _handleAnthropicGeneration.apply(this, arguments);\n      }\n      return handleAnthropicGeneration;\n    }()\n  }, {\n    key: \"getProvider\",\n    value: function getProvider() {\n      return this.currentProvider;\n    }\n  }, {\n    key: \"getBaseUrl\",\n    value: function getBaseUrl() {\n      return this.baseUrl;\n    }\n  }, {\n    key: \"isConfigured\",\n    value: function isConfigured() {\n      return !!(this.openAIClient || this.anthropicClient || this.customClient);\n    }\n  }], [{\n    key: \"getInstance\",\n    value: function getInstance() {\n      if (!AIService.instance) {\n        AIService.instance = new AIService();\n      }\n      return AIService.instance;\n    }\n  }]);\n}();\nexport var aiService = AIService.getInstance();","map":{"version":3,"names":["OpenAI","Anthropic","AIService","_classCallCheck","openAIClient","anthropicClient","customClient","currentProvider","baseUrl","loadSavedConfig","_createClass","key","value","savedConfig","localStorage","getItem","config","JSON","parse","configure","catch","console","error","_configure","_asyncToGenerator","provider","apiKey","dangerouslyAllowBrowser","models","list","Error","baseURL","setItem","stringify","message","_x","apply","arguments","_getAvailableModels","response","data","map","model","id","name","getAvailableModels","_generateText","prompt","options","length","undefined","handleOpenAIGeneration","handleAnthropicGeneration","generateText","_x2","_handleOpenAIGeneration","client","chat","completions","create","messages","role","content","temperature","max_tokens","maxTokens","stream","fullResponse","_iteratorAbruptCompletion","_didIteratorError","_iteratorError","_iterator","_asyncIterator","_step","next","done","chunk","_chunk$choices$","_chunk$choices$$delta","choices","delta","onToken","err","return","_response$choices$","_response$choices$$me","_x3","_x4","_handleAnthropicGeneration","text","_x5","_x6","getProvider","getBaseUrl","isConfigured","getInstance","instance","aiService"],"sources":["/home/project/src/services/aiService.ts"],"sourcesContent":["import OpenAI from 'openai';\nimport Anthropic from '@anthropic-ai/sdk';\n\ninterface AIServiceConfig {\n  provider: 'openai' | 'anthropic' | 'custom';\n  apiKey: string;\n  baseUrl?: string;\n  model?: string;\n}\n\nexport interface Model {\n  name: string;\n  id: string;\n  provider: Provider;\n}\n\nexport type Provider = \"openai\" | \"anthropic\" | \"custom\";\n\nclass AIService {\n  private static instance: AIService;\n  private openAIClient: OpenAI | null = null;\n  private anthropicClient: Anthropic | null = null;\n  private customClient: OpenAI | null = null;\n  private currentProvider: Provider = 'openai';\n  private baseUrl: string | null = null;\n\n  private constructor() {\n    this.loadSavedConfig();\n  }\n\n  private loadSavedConfig() {\n    const savedConfig = localStorage.getItem('ai_service_config');\n    if (savedConfig) {\n      const config = JSON.parse(savedConfig);\n      this.configure(config).catch(console.error);\n    }\n  }\n\n  static getInstance(): AIService {\n    if (!AIService.instance) {\n      AIService.instance = new AIService();\n    }\n    return AIService.instance;\n  }\n\n  async configure(config: AIServiceConfig): Promise<void> {\n    try {\n      switch (config.provider) {\n        case 'openai':\n          this.openAIClient = new OpenAI({\n            apiKey: config.apiKey,\n            dangerouslyAllowBrowser: true\n          });\n          await this.openAIClient.models.list(); // Test connection\n          break;\n\n        case 'anthropic':\n          this.anthropicClient = new Anthropic({\n            apiKey: config.apiKey\n          });\n          break;\n\n        case 'custom':\n          if (!config.baseUrl) {\n            throw new Error('Base URL is required for custom provider');\n          }\n          this.customClient = new OpenAI({\n            apiKey: config.apiKey || 'not-needed',\n            baseURL: config.baseUrl,\n            dangerouslyAllowBrowser: true\n          });\n          break;\n      }\n\n      this.currentProvider = config.provider;\n      this.baseUrl = config.baseUrl || null;\n      \n      // Save configuration\n      localStorage.setItem('ai_service_config', JSON.stringify({\n        provider: config.provider,\n        apiKey: config.apiKey,\n        baseUrl: config.baseUrl\n      }));\n    } catch (error) {\n      throw new Error(`Failed to configure AI service: ${error.message}`);\n    }\n  }\n\n  async getAvailableModels(): Promise<Model[]> {\n    try {\n      switch (this.currentProvider) {\n        case 'openai':\n          if (this.openAIClient) {\n            const response = await this.openAIClient.models.list();\n            return response.data.map(model => ({\n              id: model.id,\n              name: model.id,\n              provider: 'openai'\n            }));\n          }\n          break;\n\n        case 'anthropic':\n          if (this.anthropicClient) {\n            return [\n              {\n                id: 'claude-2',\n                name: 'Claude 2',\n                provider: 'anthropic'\n              },\n              {\n                id: 'claude-instant-1',\n                name: 'Claude Instant',\n                provider: 'anthropic'\n              }\n            ];\n          }\n          break;\n\n        case 'custom':\n          if (this.customClient) {\n            try {\n              const response = await this.customClient.models.list();\n              return response.data.map(model => ({\n                id: model.id,\n                name: model.id,\n                provider: 'custom'\n              }));\n            } catch (error) {\n              // If model list fails, return a default model\n              return [{\n                id: 'default-model',\n                name: 'Default Model',\n                provider: 'custom'\n              }];\n            }\n          }\n          break;\n      }\n      return [];\n    } catch (error) {\n      console.error('Failed to fetch models:', error);\n      return [];\n    }\n  }\n\n  async generateText(prompt: string, options: {\n    model?: string;\n    maxTokens?: number;\n    temperature?: number;\n    stream?: boolean;\n    onToken?: (token: string) => void;\n  } = {}) {\n    try {\n      switch (this.currentProvider) {\n        case 'openai':\n          if (this.openAIClient) {\n            return this.handleOpenAIGeneration(prompt, options);\n          }\n          break;\n\n        case 'anthropic':\n          if (this.anthropicClient) {\n            return this.handleAnthropicGeneration(prompt, options);\n          }\n          break;\n\n        case 'custom':\n          if (this.customClient) {\n            return this.handleOpenAIGeneration(prompt, options, this.customClient);\n          }\n          break;\n      }\n\n      throw new Error('No AI provider configured');\n    } catch (error) {\n      throw new Error(`AI generation failed: ${error.message}`);\n    }\n  }\n\n  private async handleOpenAIGeneration(\n    prompt: string,\n    options: any,\n    client: OpenAI = this.openAIClient!\n  ) {\n    const response = await client.chat.completions.create({\n      model: options.model || 'gpt-3.5-turbo',\n      messages: [{ role: 'user', content: prompt }],\n      temperature: options.temperature,\n      max_tokens: options.maxTokens,\n      stream: options.stream\n    });\n\n    if (options.stream) {\n      let fullResponse = '';\n      for await (const chunk of response) {\n        const content = chunk.choices[0]?.delta?.content || '';\n        fullResponse += content;\n        options.onToken?.(content);\n      }\n      return fullResponse;\n    } else {\n      return response.choices[0]?.message?.content || '';\n    }\n  }\n\n  private async handleAnthropicGeneration(prompt: string, options: any) {\n    const response = await this.anthropicClient!.messages.create({\n      model: options.model || 'claude-2',\n      max_tokens: options.maxTokens,\n      messages: [{\n        role: 'user',\n        content: prompt\n      }]\n    });\n    return response.content[0].text;\n  }\n\n  getProvider() {\n    return this.currentProvider;\n  }\n\n  getBaseUrl() {\n    return this.baseUrl;\n  }\n\n  isConfigured() {\n    return !!(this.openAIClient || this.anthropicClient || this.customClient);\n  }\n}\n\nexport const aiService = AIService.getInstance();\n"],"mappings":";;;;;AAAA,OAAOA,MAAM,MAAM,QAAQ;AAC3B,OAAOC,SAAS,MAAM,mBAAmB;AAAC,IAiBpCC,SAAS;EAQb,SAAAA,UAAA,EAAsB;IAAAC,eAAA,OAAAD,SAAA;IAAA,KANdE,YAAY,GAAkB,IAAI;IAAA,KAClCC,eAAe,GAAqB,IAAI;IAAA,KACxCC,YAAY,GAAkB,IAAI;IAAA,KAClCC,eAAe,GAAa,QAAQ;IAAA,KACpCC,OAAO,GAAkB,IAAI;IAGnC,IAAI,CAACC,eAAe,CAAC,CAAC;EACxB;EAAC,OAAAC,YAAA,CAAAR,SAAA;IAAAS,GAAA;IAAAC,KAAA,EAED,SAAQH,eAAeA,CAAA,EAAG;MACxB,IAAMI,WAAW,GAAGC,YAAY,CAACC,OAAO,CAAC,mBAAmB,CAAC;MAC7D,IAAIF,WAAW,EAAE;QACf,IAAMG,MAAM,GAAGC,IAAI,CAACC,KAAK,CAACL,WAAW,CAAC;QACtC,IAAI,CAACM,SAAS,CAACH,MAAM,CAAC,CAACI,KAAK,CAACC,OAAO,CAACC,KAAK,CAAC;MAC7C;IACF;EAAC;IAAAX,GAAA;IAAAC,KAAA;MAAA,IAAAW,UAAA,GAAAC,iBAAA,CASD,WAAgBR,MAAuB,EAAiB;QACtD,IAAI;UACF,QAAQA,MAAM,CAACS,QAAQ;YACrB,KAAK,QAAQ;cACX,IAAI,CAACrB,YAAY,GAAG,IAAIJ,MAAM,CAAC;gBAC7B0B,MAAM,EAAEV,MAAM,CAACU,MAAM;gBACrBC,uBAAuB,EAAE;cAC3B,CAAC,CAAC;cACF,MAAM,IAAI,CAACvB,YAAY,CAACwB,MAAM,CAACC,IAAI,CAAC,CAAC;cACrC;YAEF,KAAK,WAAW;cACd,IAAI,CAACxB,eAAe,GAAG,IAAIJ,SAAS,CAAC;gBACnCyB,MAAM,EAAEV,MAAM,CAACU;cACjB,CAAC,CAAC;cACF;YAEF,KAAK,QAAQ;cACX,IAAI,CAACV,MAAM,CAACR,OAAO,EAAE;gBACnB,MAAM,IAAIsB,KAAK,CAAC,0CAA0C,CAAC;cAC7D;cACA,IAAI,CAACxB,YAAY,GAAG,IAAIN,MAAM,CAAC;gBAC7B0B,MAAM,EAAEV,MAAM,CAACU,MAAM,IAAI,YAAY;gBACrCK,OAAO,EAAEf,MAAM,CAACR,OAAO;gBACvBmB,uBAAuB,EAAE;cAC3B,CAAC,CAAC;cACF;UACJ;UAEA,IAAI,CAACpB,eAAe,GAAGS,MAAM,CAACS,QAAQ;UACtC,IAAI,CAACjB,OAAO,GAAGQ,MAAM,CAACR,OAAO,IAAI,IAAI;UAGrCM,YAAY,CAACkB,OAAO,CAAC,mBAAmB,EAAEf,IAAI,CAACgB,SAAS,CAAC;YACvDR,QAAQ,EAAET,MAAM,CAACS,QAAQ;YACzBC,MAAM,EAAEV,MAAM,CAACU,MAAM;YACrBlB,OAAO,EAAEQ,MAAM,CAACR;UAClB,CAAC,CAAC,CAAC;QACL,CAAC,CAAC,OAAOc,KAAK,EAAE;UACd,MAAM,IAAIQ,KAAK,CAAC,mCAAmCR,KAAK,CAACY,OAAO,EAAE,CAAC;QACrE;MACF,CAAC;MAAA,SAzCKf,SAASA,CAAAgB,EAAA;QAAA,OAAAZ,UAAA,CAAAa,KAAA,OAAAC,SAAA;MAAA;MAAA,OAATlB,SAAS;IAAA;EAAA;IAAAR,GAAA;IAAAC,KAAA;MAAA,IAAA0B,mBAAA,GAAAd,iBAAA,CA2Cf,aAA6C;QAC3C,IAAI;UACF,QAAQ,IAAI,CAACjB,eAAe;YAC1B,KAAK,QAAQ;cACX,IAAI,IAAI,CAACH,YAAY,EAAE;gBACrB,IAAMmC,QAAQ,SAAS,IAAI,CAACnC,YAAY,CAACwB,MAAM,CAACC,IAAI,CAAC,CAAC;gBACtD,OAAOU,QAAQ,CAACC,IAAI,CAACC,GAAG,CAAC,UAAAC,KAAK;kBAAA,OAAK;oBACjCC,EAAE,EAAED,KAAK,CAACC,EAAE;oBACZC,IAAI,EAAEF,KAAK,CAACC,EAAE;oBACdlB,QAAQ,EAAE;kBACZ,CAAC;gBAAA,CAAC,CAAC;cACL;cACA;YAEF,KAAK,WAAW;cACd,IAAI,IAAI,CAACpB,eAAe,EAAE;gBACxB,OAAO,CACL;kBACEsC,EAAE,EAAE,UAAU;kBACdC,IAAI,EAAE,UAAU;kBAChBnB,QAAQ,EAAE;gBACZ,CAAC,EACD;kBACEkB,EAAE,EAAE,kBAAkB;kBACtBC,IAAI,EAAE,gBAAgB;kBACtBnB,QAAQ,EAAE;gBACZ,CAAC,CACF;cACH;cACA;YAEF,KAAK,QAAQ;cACX,IAAI,IAAI,CAACnB,YAAY,EAAE;gBACrB,IAAI;kBACF,IAAMiC,SAAQ,SAAS,IAAI,CAACjC,YAAY,CAACsB,MAAM,CAACC,IAAI,CAAC,CAAC;kBACtD,OAAOU,SAAQ,CAACC,IAAI,CAACC,GAAG,CAAC,UAAAC,KAAK;oBAAA,OAAK;sBACjCC,EAAE,EAAED,KAAK,CAACC,EAAE;sBACZC,IAAI,EAAEF,KAAK,CAACC,EAAE;sBACdlB,QAAQ,EAAE;oBACZ,CAAC;kBAAA,CAAC,CAAC;gBACL,CAAC,CAAC,OAAOH,KAAK,EAAE;kBAEd,OAAO,CAAC;oBACNqB,EAAE,EAAE,eAAe;oBACnBC,IAAI,EAAE,eAAe;oBACrBnB,QAAQ,EAAE;kBACZ,CAAC,CAAC;gBACJ;cACF;cACA;UACJ;UACA,OAAO,EAAE;QACX,CAAC,CAAC,OAAOH,KAAK,EAAE;UACdD,OAAO,CAACC,KAAK,CAAC,yBAAyB,EAAEA,KAAK,CAAC;UAC/C,OAAO,EAAE;QACX;MACF,CAAC;MAAA,SAxDKuB,kBAAkBA,CAAA;QAAA,OAAAP,mBAAA,CAAAF,KAAA,OAAAC,SAAA;MAAA;MAAA,OAAlBQ,kBAAkB;IAAA;EAAA;IAAAlC,GAAA;IAAAC,KAAA;MAAA,IAAAkC,aAAA,GAAAtB,iBAAA,CA0DxB,WAAmBuB,MAAc,EAMzB;QAAA,IAN2BC,OAMlC,GAAAX,SAAA,CAAAY,MAAA,QAAAZ,SAAA,QAAAa,SAAA,GAAAb,SAAA,MAAG,CAAC,CAAC;QACJ,IAAI;UACF,QAAQ,IAAI,CAAC9B,eAAe;YAC1B,KAAK,QAAQ;cACX,IAAI,IAAI,CAACH,YAAY,EAAE;gBACrB,OAAO,IAAI,CAAC+C,sBAAsB,CAACJ,MAAM,EAAEC,OAAO,CAAC;cACrD;cACA;YAEF,KAAK,WAAW;cACd,IAAI,IAAI,CAAC3C,eAAe,EAAE;gBACxB,OAAO,IAAI,CAAC+C,yBAAyB,CAACL,MAAM,EAAEC,OAAO,CAAC;cACxD;cACA;YAEF,KAAK,QAAQ;cACX,IAAI,IAAI,CAAC1C,YAAY,EAAE;gBACrB,OAAO,IAAI,CAAC6C,sBAAsB,CAACJ,MAAM,EAAEC,OAAO,EAAE,IAAI,CAAC1C,YAAY,CAAC;cACxE;cACA;UACJ;UAEA,MAAM,IAAIwB,KAAK,CAAC,2BAA2B,CAAC;QAC9C,CAAC,CAAC,OAAOR,KAAK,EAAE;UACd,MAAM,IAAIQ,KAAK,CAAC,yBAAyBR,KAAK,CAACY,OAAO,EAAE,CAAC;QAC3D;MACF,CAAC;MAAA,SAhCKmB,YAAYA,CAAAC,GAAA;QAAA,OAAAR,aAAA,CAAAV,KAAA,OAAAC,SAAA;MAAA;MAAA,OAAZgB,YAAY;IAAA;EAAA;IAAA1C,GAAA;IAAAC,KAAA;MAAA,IAAA2C,uBAAA,GAAA/B,iBAAA,CAkClB,WACEuB,MAAc,EACdC,OAAY,EAEZ;QAAA,IADAQ,MAAc,GAAAnB,SAAA,CAAAY,MAAA,QAAAZ,SAAA,QAAAa,SAAA,GAAAb,SAAA,MAAG,IAAI,CAACjC,YAAY;QAElC,IAAMmC,QAAQ,SAASiB,MAAM,CAACC,IAAI,CAACC,WAAW,CAACC,MAAM,CAAC;UACpDjB,KAAK,EAAEM,OAAO,CAACN,KAAK,IAAI,eAAe;UACvCkB,QAAQ,EAAE,CAAC;YAAEC,IAAI,EAAE,MAAM;YAAEC,OAAO,EAAEf;UAAO,CAAC,CAAC;UAC7CgB,WAAW,EAAEf,OAAO,CAACe,WAAW;UAChCC,UAAU,EAAEhB,OAAO,CAACiB,SAAS;UAC7BC,MAAM,EAAElB,OAAO,CAACkB;QAClB,CAAC,CAAC;QAEF,IAAIlB,OAAO,CAACkB,MAAM,EAAE;UAClB,IAAIC,YAAY,GAAG,EAAE;UAAC,IAAAC,yBAAA;UAAA,IAAAC,iBAAA;UAAA,IAAAC,cAAA;UAAA;YACtB,SAAAC,SAAA,GAAAC,cAAA,CAA0BjC,QAAQ,GAAAkC,KAAA,EAAAL,yBAAA,KAAAK,KAAA,SAAAF,SAAA,CAAAG,IAAA,IAAAC,IAAA,EAAAP,yBAAA,UAAE;cAAA,IAAnBQ,KAAK,GAAAH,KAAA,CAAA7D,KAAA;cAAA;gBAAA,IAAAiE,eAAA,EAAAC,qBAAA;gBACpB,IAAMhB,OAAO,GAAG,EAAAe,eAAA,GAAAD,KAAK,CAACG,OAAO,CAAC,CAAC,CAAC,sBAAAD,qBAAA,GAAhBD,eAAA,CAAkBG,KAAK,qBAAvBF,qBAAA,CAAyBhB,OAAO,KAAI,EAAE;gBACtDK,YAAY,IAAIL,OAAO;gBACvBd,OAAO,CAACiC,OAAO,oBAAfjC,OAAO,CAACiC,OAAO,CAAGnB,OAAO,CAAC;cAAC;YAC7B;UAAC,SAAAoB,GAAA;YAAAb,iBAAA;YAAAC,cAAA,GAAAY,GAAA;UAAA;YAAA;cAAA,IAAAd,yBAAA,IAAAG,SAAA,CAAAY,MAAA;gBAAA,MAAAZ,SAAA,CAAAY,MAAA;cAAA;YAAA;cAAA,IAAAd,iBAAA;gBAAA,MAAAC,cAAA;cAAA;YAAA;UAAA;UACD,OAAOH,YAAY;QACrB,CAAC,MAAM;UAAA,IAAAiB,kBAAA,EAAAC,qBAAA;UACL,OAAO,EAAAD,kBAAA,GAAA7C,QAAQ,CAACwC,OAAO,CAAC,CAAC,CAAC,sBAAAM,qBAAA,GAAnBD,kBAAA,CAAqBlD,OAAO,qBAA5BmD,qBAAA,CAA8BvB,OAAO,KAAI,EAAE;QACpD;MACF,CAAC;MAAA,SAxBaX,sBAAsBA,CAAAmC,GAAA,EAAAC,GAAA;QAAA,OAAAhC,uBAAA,CAAAnB,KAAA,OAAAC,SAAA;MAAA;MAAA,OAAtBc,sBAAsB;IAAA;EAAA;IAAAxC,GAAA;IAAAC,KAAA;MAAA,IAAA4E,0BAAA,GAAAhE,iBAAA,CA0BpC,WAAwCuB,MAAc,EAAEC,OAAY,EAAE;QACpE,IAAMT,QAAQ,SAAS,IAAI,CAAClC,eAAe,CAAEuD,QAAQ,CAACD,MAAM,CAAC;UAC3DjB,KAAK,EAAEM,OAAO,CAACN,KAAK,IAAI,UAAU;UAClCsB,UAAU,EAAEhB,OAAO,CAACiB,SAAS;UAC7BL,QAAQ,EAAE,CAAC;YACTC,IAAI,EAAE,MAAM;YACZC,OAAO,EAAEf;UACX,CAAC;QACH,CAAC,CAAC;QACF,OAAOR,QAAQ,CAACuB,OAAO,CAAC,CAAC,CAAC,CAAC2B,IAAI;MACjC,CAAC;MAAA,SAVarC,yBAAyBA,CAAAsC,GAAA,EAAAC,GAAA;QAAA,OAAAH,0BAAA,CAAApD,KAAA,OAAAC,SAAA;MAAA;MAAA,OAAzBe,yBAAyB;IAAA;EAAA;IAAAzC,GAAA;IAAAC,KAAA,EAYvC,SAAAgF,WAAWA,CAAA,EAAG;MACZ,OAAO,IAAI,CAACrF,eAAe;IAC7B;EAAC;IAAAI,GAAA;IAAAC,KAAA,EAED,SAAAiF,UAAUA,CAAA,EAAG;MACX,OAAO,IAAI,CAACrF,OAAO;IACrB;EAAC;IAAAG,GAAA;IAAAC,KAAA,EAED,SAAAkF,YAAYA,CAAA,EAAG;MACb,OAAO,CAAC,EAAE,IAAI,CAAC1F,YAAY,IAAI,IAAI,CAACC,eAAe,IAAI,IAAI,CAACC,YAAY,CAAC;IAC3E;EAAC;IAAAK,GAAA;IAAAC,KAAA,EA9LD,SAAOmF,WAAWA,CAAA,EAAc;MAC9B,IAAI,CAAC7F,SAAS,CAAC8F,QAAQ,EAAE;QACvB9F,SAAS,CAAC8F,QAAQ,GAAG,IAAI9F,SAAS,CAAC,CAAC;MACtC;MACA,OAAOA,SAAS,CAAC8F,QAAQ;IAC3B;EAAC;AAAA;AA4LH,OAAO,IAAMC,SAAS,GAAG/F,SAAS,CAAC6F,WAAW,CAAC,CAAC","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}